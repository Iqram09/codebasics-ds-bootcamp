{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db972a9",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style=\"color:blue\">Codebasics Python Course: Exercise - JSON, Generators, Decorators</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e6c089-394e-4180-80c9-95e8aa647171",
   "metadata": {},
   "source": [
    "**Loki** appreciates and conveys thank you for the help you provided with his previous ad-hoc tasks.\n",
    "\n",
    "As you've handled things well, he has some slightly more advanced ad-hoc tasks for you below.\n",
    "\n",
    "Have fun working on them! ðŸ˜œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff4e7d",
   "metadata": {},
   "source": [
    "### Task 1: Client Sales Data\n",
    "\n",
    "**Scenario:**  One of the Python developers, who was handling a retail client, went on vacation. However, the client has an urgent requirement to understand their sales data. Loki reached out to you for help with this. The sales records are stored in JSON format, detailing products, quantities sold, and sales categories.\n",
    "\n",
    "\n",
    "1. Load sales data from ```sales_data.json``` into a dictionary.\n",
    "\n",
    "   \n",
    "This task helps you provide actionable business insights from raw sales data."
   ]
  },
  {
   "cell_type": "code",
   "id": "58c1c79a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T10:12:12.033063Z",
     "start_time": "2025-03-07T10:12:12.019509Z"
    }
   },
   "source": [
    "# write your code here\n",
    "import json\n",
    "\n",
    "with open(\"sales_data.json\", \"r\") as f:\n",
    "    sales_data = json.load(f)\n",
    "print(sales_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'product': 'Laptop', 'category': 'Electronics', 'quantity': 15, 'price_per_unit': 1200}, {'product': 'Jeans', 'category': 'Apparel', 'quantity': 40, 'price_per_unit': 50}, {'product': 'Blender', 'category': 'Home Appliances', 'quantity': 25, 'price_per_unit': 150}, {'product': 'Smartphone', 'category': 'Electronics', 'quantity': 30, 'price_per_unit': 800}, {'product': 'Jacket', 'category': 'Apparel', 'quantity': 20, 'price_per_unit': 120}]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "a8a49eba",
   "metadata": {},
   "source": [
    "### Task 2: Calculate and Display Total Sales by Category\n",
    "\n",
    "**Scenario:** Continuing your role, after successfully loading and organizing the sales data from a retail client, your next step is to provide a breakdown of total sales per category.\n",
    "\n",
    "1. Aggregate this data by product category to calculate total sales per category.\n",
    "2. Print the results, showing the total sales for each product category."
   ]
  },
  {
   "cell_type": "code",
   "id": "cec25c2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T10:13:13.514226Z",
     "start_time": "2025-03-07T10:13:13.508429Z"
    }
   },
   "source": [
    "# write your code here\n",
    "category_sales = {}\n",
    "for sale in sales_data:\n",
    "    category = sale[\"category\"]\n",
    "    quantity = sale[\"quantity\"]\n",
    "    if category not in category_sales:\n",
    "        category_sales[category] = 0\n",
    "    category_sales[category] += quantity\n",
    "    print(f\"{category}: {category_sales[category]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electronics: 15\n",
      "Apparel: 40\n",
      "Home Appliances: 25\n",
      "Electronics: 45\n",
      "Apparel: 60\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "4edb28b4",
   "metadata": {},
   "source": [
    "### Task 3: Output Aggregated Sales Data to JSON File\n",
    "\n",
    "**Scenario:** Building on your previous work, where you calculated total sales by category, your client now requires this information in a structured digital format for integration into their business systems.\n",
    "\n",
    "1. Generate a JSON file named ```aggregated_sales.json``` containing the total sales data by category.\n",
    "2. Ensure the data is formatted as a list of dictionaries, each representing a category and its corresponding total sales.\n",
    "   \n",
    "**Expected JSON Output Format:**\n",
    "\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"category\": \"Electronics\",\n",
    "        \"total_sales\": 42000\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Apparel\",\n",
    "        \"total_sales\": 4400\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Home Appliances\",\n",
    "        \"total_sales\": 3750\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "1a000254",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T10:22:33.050250Z",
     "start_time": "2025-03-07T10:22:33.045500Z"
    }
   },
   "source": [
    "# write your code here\n",
    "aggregated_sales = [{\n",
    "    \"category\": category,\n",
    "    \"total_sales\": category_sales[category]\n",
    "} for category in category_sales]\n",
    "print(aggregated_sales)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'category': 'Electronics', 'total_sales': 45}, {'category': 'Apparel', 'total_sales': 60}, {'category': 'Home Appliances', 'total_sales': 25}]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T10:22:34.107730Z",
     "start_time": "2025-03-07T10:22:34.103646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"aggregated_sales.json\", \"w\") as f:\n",
    "    json.dump(aggregated_sales, f, indent=4)"
   ],
   "id": "538369abdf3b7479",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "fcada7bc",
   "metadata": {},
   "source": [
    "### Task 4: Monitor and Filter Temperature Readings\n",
    "\n",
    "**Scenario:** At **AtliQ**, your next ad-hoc task involves monitoring equipment sensor data to promptly identify any readings that suggest potential overheating. The sensor data file ```sensor_data.txt``` is so HUGE that you can't read it all at once (For this exercise we have given a small file but just assume that in real life such a file will be pretty HUGE).\n",
    "\n",
    "**Objective:** Develop a Python program with a generator function `read_and_filter_temperatures` that efficiently processes this large dataset by:\n",
    "\n",
    "1. Taking two parameters: ```filename``` (the name of the sensor data file) and ```threshold``` (the temperature limit that indicates overheating).\n",
    "2. Yielding temperatures that exceed the specified threshold.\n",
    "3. Printing each critical temperature reading as it's identified to allow immediate action."
   ]
  },
  {
   "cell_type": "code",
   "id": "76aea479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T10:27:31.618015Z",
     "start_time": "2025-03-07T10:27:31.612689Z"
    }
   },
   "source": [
    "# write your code here\n",
    "def read_and_filter_temperatures(filename, threshold):\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            temperature = float(parts[1])\n",
    "            if temperature > threshold:\n",
    "                yield temperature\n",
    "filename = \"sensor_data.txt\"\n",
    "threshold = 20.0\n",
    "filtered_temperatures = read_and_filter_temperatures(filename, threshold)\n",
    "\n",
    "print(\"Critical Temperatures:\")\n",
    "for temperature in filtered_temperatures:\n",
    "    print(temperature)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Temperatures:\n",
      "21.8\n",
      "22.5\n",
      "24.1\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "a1e66533",
   "metadata": {},
   "source": [
    "### Task 5: Optimize API Usage with Caching for Client Financial Data Retrieval\n",
    "\n",
    "At AtliQ, you have been assigned to work on a new ad-hoc task for a client project involving a FINTECH company. Your task is to retrieve the company name based on the company's ticker. For example, for the ticker \"AAPL\", the company name will be \"Apple Inc.\". \n",
    "\n",
    "You are using the Bloomberg API for this, and each API call costs money. To reduce expenses, you want to implement a caching function using a decorator so that if a company name has previously been retrieved, it will be fetched from the cache; otherwise, an API call will be made. We don't have an actual API for this exercise, but we've provided you with a function called `get_company_name`, for which you can assume that every call incurs a cost, and your goal is to minimize the number of calls.\n",
    "\n",
    "You will write a decorator,\n",
    "\n",
    "```\n",
    "def cache_decorator(func):\n",
    "```\n",
    "\n",
    "And annotate the main function\n",
    "```\n",
    "@cache_decorator\n",
    "def get_company_name(ticker):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "168dcaf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T10:29:53.885674Z",
     "start_time": "2025-03-07T10:29:53.882099Z"
    }
   },
   "source": [
    "def get_company_name(ticker):\n",
    "    \"\"\"Simulated API function to fetch a company name based on the ticker symbol.\"\"\"\n",
    "    # Simulate different responses based on the ticker symbol\n",
    "    api_responses = {\n",
    "        \"AAPL\": \"Apple Inc.\",\n",
    "        \"MSFT\": \"Microsoft Corporation\",\n",
    "        \"GOOGL\": \"Alphabet Inc.\"\n",
    "    }\n",
    "    return api_responses.get(ticker, \"Unknown Company\")"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "7ee2dedc-9044-4e62-8353-c6458efdd92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T10:29:55.142238Z",
     "start_time": "2025-03-07T10:29:55.136629Z"
    }
   },
   "source": [
    "def cache_decorator(func):\n",
    "    cache = {}\n",
    "    def wrapper(ticker):\n",
    "        if ticker in cache:\n",
    "            print(f\"Cache hit for {ticker}\")\n",
    "            return cache[ticker]\n",
    "        else:\n",
    "            print(f\"API call for {ticker}\")\n",
    "            result = func(ticker)\n",
    "            cache[ticker] = result\n",
    "            return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@cache_decorator\n",
    "def get_company_name(ticker):\n",
    "    api_responses = {\n",
    "        \"AAPL\": \"Apple Inc.\",\n",
    "        \"MSFT\": \"Microsoft Corporation\",\n",
    "        \"GOOGL\": \"Alphabet Inc.\"\n",
    "        }\n",
    "    return api_responses.get(ticker, \"Unknown Company\")\n",
    "\n",
    "# Test the decorated function\n",
    "print(get_company_name(\"AAPL\"))  # Expected to trigger an API call\n",
    "print(get_company_name(\"AAPL\"))  # Expected to use cached data\n",
    "print(get_company_name(\"MSFT\"))  # Expected to trigger an API call\n",
    "print(get_company_name(\"MSFT\"))  # Expected to use cached data\n",
    "print(get_company_name(\"GOOGL\"))  # Expected to trigger an API call\n",
    "print(get_company_name(\"GOOGL\"))  # Expected to use cached data"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call for AAPL\n",
      "Apple Inc.\n",
      "Cache hit for AAPL\n",
      "Apple Inc.\n",
      "API call for MSFT\n",
      "Microsoft Corporation\n",
      "Cache hit for MSFT\n",
      "Microsoft Corporation\n",
      "API call for GOOGL\n",
      "Alphabet Inc.\n",
      "Cache hit for GOOGL\n",
      "Alphabet Inc.\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
